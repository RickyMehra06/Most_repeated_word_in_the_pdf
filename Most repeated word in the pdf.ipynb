{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e55552",
   "metadata": {},
   "source": [
    "## The most repeated word in the pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1ba1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import spacy\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9a8b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15 pages in the given pdf file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Understanding Random ForestThis article was pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Boosting– It combines weak learners into st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now the model (Model 01, Model 02, and Model 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steps involved in random forest algorithm:Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Important Features of Random Forest1. Diversit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3. oob_score – OOB means out of the bag. It is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from sklearn.ensemble import RandomForestClass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rf_best = grid_search.best_estimator_ rf_bestF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>from sklearn.tree import plot_tree plt.figure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The trees created by estimators_[5] and estima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.  It can be used in classification and regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The media shown in this article are not owned ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   Understanding Random ForestThis article was pu...\n",
       "1   2. Boosting– It combines weak learners into st...\n",
       "2   Now the model (Model 01, Model 02, and Model 0...\n",
       "3    Steps involved in random forest algorithm:Ste...\n",
       "4   Important Features of Random Forest1. Diversit...\n",
       "5   3. oob_score – OOB means out of the bag. It is...\n",
       "6   from sklearn.ensemble import RandomForestClass...\n",
       "7   rf_best = grid_search.best_estimator_ rf_bestF...\n",
       "8    from sklearn.tree import plot_tree plt.figure...\n",
       "9   The trees created by estimators_[5] and estima...\n",
       "10  1.  It can be used in classification and regre...\n",
       "11  The media shown in this article are not owned ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/Users/ricky/Downloads/RandomForest.pdf\"\n",
    "\n",
    "pdf_reader = PyPDF2.PdfReader(path)\n",
    "print(f\"There are {len(pdf_reader.pages)} pages in the given pdf file\")\n",
    "\n",
    "text_list = []\n",
    "\n",
    "for page in range(len(pdf_reader.pages)):\n",
    "    page_text = pdf_reader.pages[page].extract_text()    \n",
    "    page_text = page_text.replace(\"\\n\", \"\").replace(\"  \", \" \") # To Clean the extracted text (remove newlines and extra spaces)\n",
    "    if page_text.strip():  # Check if page_text is not empty or contains only whitespace\n",
    "        text_list.append(page_text)\n",
    "\n",
    "df = pd.DataFrame(text_list, columns=['text'])\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c6b59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Understanding Random ForestThis article was pu...</td>\n",
       "      <td>understand random forestthis article publish d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Boosting– It combines weak learners into st...</td>\n",
       "      <td>2 boost – combine weak learner strong learner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now the model (Model 01, Model 02, and Model 0...</td>\n",
       "      <td>model model 01 model 02 model 03 obtain bootst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steps involved in random forest algorithm:Ste...</td>\n",
       "      <td>step involve random forest algorithm step 1 ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Important Features of Random Forest1. Diversit...</td>\n",
       "      <td>important features random forest1 diversity- a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3. oob_score – OOB means out of the bag. It is...</td>\n",
       "      <td>3 oob_score – oob mean bag random forest cross...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from sklearn.ensemble import RandomForestClass...</td>\n",
       "      <td>sklearn.ensemble import randomforestclassifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rf_best = grid_search.best_estimator_ rf_bestF...</td>\n",
       "      <td>rf_b grid_search.best_estimator rf_bestfrom hy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>from sklearn.tree import plot_tree plt.figure...</td>\n",
       "      <td>sklearn.tree import plot_tree plt.figure(figsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The trees created by estimators_[5] and estima...</td>\n",
       "      <td>tree create estimators_[5 estimators_[7 differ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Understanding Random ForestThis article was pu...   \n",
       "1  2. Boosting– It combines weak learners into st...   \n",
       "2  Now the model (Model 01, Model 02, and Model 0...   \n",
       "3   Steps involved in random forest algorithm:Ste...   \n",
       "4  Important Features of Random Forest1. Diversit...   \n",
       "5  3. oob_score – OOB means out of the bag. It is...   \n",
       "6  from sklearn.ensemble import RandomForestClass...   \n",
       "7  rf_best = grid_search.best_estimator_ rf_bestF...   \n",
       "8   from sklearn.tree import plot_tree plt.figure...   \n",
       "9  The trees created by estimators_[5] and estima...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  understand random forestthis article publish d...  \n",
       "1  2 boost – combine weak learner strong learner ...  \n",
       "2  model model 01 model 02 model 03 obtain bootst...  \n",
       "3  step involve random forest algorithm step 1 ra...  \n",
       "4  important features random forest1 diversity- a...  \n",
       "5  3 oob_score – oob mean bag random forest cross...  \n",
       "6  sklearn.ensemble import randomforestclassifier...  \n",
       "7  rf_b grid_search.best_estimator rf_bestfrom hy...  \n",
       "8  sklearn.tree import plot_tree plt.figure(figsi...  \n",
       "9  tree create estimators_[5 estimators_[7 differ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    tokens = nlp(text)\n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != '-PRON-' else word.lower_ for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    tokens = ' '.join(tokens)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef9c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"datasets/PDF_text_data.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c042a35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['understand',\n",
       " 'random',\n",
       " 'forestthis',\n",
       " 'article',\n",
       " 'publish',\n",
       " 'data',\n",
       " 'science',\n",
       " 'blogathonintroductionrandom',\n",
       " 'forest',\n",
       " 'supervised',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithm',\n",
       " 'use',\n",
       " 'widely',\n",
       " 'classification',\n",
       " 'andregression',\n",
       " 'problem',\n",
       " 'build',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'different',\n",
       " 'sample',\n",
       " 'majority',\n",
       " 'vote',\n",
       " 'forclassification',\n",
       " 'average',\n",
       " 'case',\n",
       " 'regression',\n",
       " 'important',\n",
       " 'feature',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'algorithm',\n",
       " 'handle',\n",
       " 'datum',\n",
       " 'setcontaine',\n",
       " 'continuous',\n",
       " 'variable',\n",
       " 'case',\n",
       " 'regression',\n",
       " 'categorical',\n",
       " 'variable',\n",
       " 'case',\n",
       " 'ofclassification',\n",
       " 'perform',\n",
       " 'result',\n",
       " 'classification',\n",
       " 'problem',\n",
       " 'real',\n",
       " 'life',\n",
       " 'analogylet',\n",
       " 'dive',\n",
       " 'real',\n",
       " 'life',\n",
       " 'analogy',\n",
       " 'understand',\n",
       " 'concept',\n",
       " 'far',\n",
       " 'student',\n",
       " 'x',\n",
       " 'want',\n",
       " 'choose',\n",
       " 'acourse',\n",
       " '10',\n",
       " '2',\n",
       " 'confused',\n",
       " 'choice',\n",
       " 'course',\n",
       " 'base',\n",
       " 'skill',\n",
       " 'set',\n",
       " 'decidesto',\n",
       " 'consult',\n",
       " 'people',\n",
       " 'like',\n",
       " 'cousin',\n",
       " 'teacher',\n",
       " 'parent',\n",
       " 'degree',\n",
       " 'student',\n",
       " 'work',\n",
       " 'people',\n",
       " 'asksthem',\n",
       " 'varied',\n",
       " 'question',\n",
       " 'like',\n",
       " 'choose',\n",
       " 'job',\n",
       " 'opportunity',\n",
       " 'course',\n",
       " 'course',\n",
       " 'fee',\n",
       " 'etc',\n",
       " 'finally',\n",
       " 'consult',\n",
       " 'people',\n",
       " 'course',\n",
       " 'decide',\n",
       " 'course',\n",
       " 'suggest',\n",
       " 'mostof',\n",
       " 'people',\n",
       " 'work',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'algorithmbefore',\n",
       " 'understand',\n",
       " 'working',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'look',\n",
       " 'ensemble',\n",
       " 'technique',\n",
       " 'ensemble',\n",
       " 'simply',\n",
       " 'mean',\n",
       " 'combine',\n",
       " 'multiple',\n",
       " 'model',\n",
       " 'collection',\n",
       " 'model',\n",
       " 'use',\n",
       " 'makeprediction',\n",
       " 'individual',\n",
       " 'model',\n",
       " 'ensemble',\n",
       " 'use',\n",
       " 'type',\n",
       " 'methods:1',\n",
       " 'bagging',\n",
       " '–',\n",
       " 'create',\n",
       " 'different',\n",
       " 'training',\n",
       " 'subset',\n",
       " 'sample',\n",
       " 'training',\n",
       " 'datum',\n",
       " 'replacement',\n",
       " 'finaloutput',\n",
       " 'base',\n",
       " 'majority',\n",
       " 'voting',\n",
       " 'example',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'advancedalgorithmclassificationmachine',\n",
       " 'learningprojectpythonregressionstructure',\n",
       " 'datasupervised',\n",
       " '2',\n",
       " 'boost',\n",
       " '–',\n",
       " 'combine',\n",
       " 'weak',\n",
       " 'learner',\n",
       " 'strong',\n",
       " 'learner',\n",
       " 'create',\n",
       " 'sequential',\n",
       " 'model',\n",
       " 'thefinal',\n",
       " 'model',\n",
       " 'high',\n",
       " 'accuracy',\n",
       " 'example',\n",
       " 'ada',\n",
       " 'boost',\n",
       " 'xg',\n",
       " 'boostas',\n",
       " 'mention',\n",
       " 'early',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'work',\n",
       " 'bagging',\n",
       " 'principle',\n",
       " 'let',\n",
       " 'dive',\n",
       " 'understandbagging',\n",
       " 'detail',\n",
       " 'baggingbagging',\n",
       " 'know',\n",
       " 'bootstrap',\n",
       " 'aggregation',\n",
       " 'ensemble',\n",
       " 'technique',\n",
       " 'use',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'baggingchoose',\n",
       " 'random',\n",
       " 'sample',\n",
       " 'datum',\n",
       " 'set',\n",
       " 'model',\n",
       " 'generate',\n",
       " 'sample',\n",
       " 'bootstrapsamples',\n",
       " 'provide',\n",
       " 'original',\n",
       " 'data',\n",
       " 'replacement',\n",
       " 'know',\n",
       " 'row',\n",
       " 'sampling',\n",
       " 'step',\n",
       " 'rowsample',\n",
       " 'replacement',\n",
       " 'bootstrap',\n",
       " 'model',\n",
       " 'train',\n",
       " 'independently',\n",
       " 'generatesresult',\n",
       " 'final',\n",
       " 'output',\n",
       " 'base',\n",
       " 'majority',\n",
       " 'voting',\n",
       " 'combine',\n",
       " 'result',\n",
       " 'model',\n",
       " 'stepwhich',\n",
       " 'involve',\n",
       " 'combine',\n",
       " 'result',\n",
       " 'generate',\n",
       " 'output',\n",
       " 'base',\n",
       " 'majority',\n",
       " 'voting',\n",
       " 'knownas',\n",
       " 'aggregation',\n",
       " 'let',\n",
       " 'look',\n",
       " 'example',\n",
       " 'break',\n",
       " 'help',\n",
       " 'follow',\n",
       " 'figure',\n",
       " 'bootstrapsample',\n",
       " 'actual',\n",
       " 'datum',\n",
       " 'bootstrap',\n",
       " 'sample',\n",
       " '01',\n",
       " 'bootstrap',\n",
       " 'sample',\n",
       " '02',\n",
       " 'bootstrap',\n",
       " 'sample',\n",
       " '03)with',\n",
       " 'replacement',\n",
       " 'mean',\n",
       " 'high',\n",
       " 'possibility',\n",
       " 'sample',\n",
       " 'contain',\n",
       " 'unique',\n",
       " 'datum',\n",
       " 'model',\n",
       " 'model',\n",
       " '01',\n",
       " 'model',\n",
       " '02',\n",
       " 'model',\n",
       " '03',\n",
       " 'obtain',\n",
       " 'bootstrap',\n",
       " 'sample',\n",
       " 'trainedindependently',\n",
       " 'model',\n",
       " 'generate',\n",
       " 'result',\n",
       " 'happy',\n",
       " 'emoji',\n",
       " 'majority',\n",
       " 'whencompare',\n",
       " 'sad',\n",
       " 'emoji',\n",
       " 'base',\n",
       " 'majority',\n",
       " 'vote',\n",
       " 'final',\n",
       " 'output',\n",
       " 'obtain',\n",
       " 'happy',\n",
       " 'emoji',\n",
       " 'step',\n",
       " 'involve',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'algorithm',\n",
       " 'step',\n",
       " '1',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'n',\n",
       " 'number',\n",
       " 'random',\n",
       " 'record',\n",
       " 'datum',\n",
       " 'set',\n",
       " 'k',\n",
       " 'number',\n",
       " 'ofrecord',\n",
       " 'step',\n",
       " '2',\n",
       " 'individual',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'construct',\n",
       " 'sample',\n",
       " 'step',\n",
       " '3',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'generate',\n",
       " 'output',\n",
       " 'step',\n",
       " '4',\n",
       " 'final',\n",
       " 'output',\n",
       " 'consider',\n",
       " 'base',\n",
       " 'majority',\n",
       " 'voting',\n",
       " 'averaging',\n",
       " 'classification',\n",
       " 'regressionrespectively',\n",
       " 'example',\n",
       " 'consider',\n",
       " 'fruit',\n",
       " 'basket',\n",
       " 'datum',\n",
       " 'figure',\n",
       " 'n',\n",
       " 'number',\n",
       " 'samplesare',\n",
       " 'fruit',\n",
       " 'basket',\n",
       " 'individual',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'construct',\n",
       " 'sample',\n",
       " 'eachdecision',\n",
       " 'tree',\n",
       " 'generate',\n",
       " 'output',\n",
       " 'figure',\n",
       " 'final',\n",
       " 'output',\n",
       " 'consider',\n",
       " 'base',\n",
       " 'onmajority',\n",
       " 'voting',\n",
       " 'figure',\n",
       " 'majority',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'output',\n",
       " 'applewhen',\n",
       " 'compare',\n",
       " 'banana',\n",
       " 'final',\n",
       " 'output',\n",
       " 'apple',\n",
       " 'important',\n",
       " 'features',\n",
       " 'random',\n",
       " 'forest1',\n",
       " 'diversity-',\n",
       " 'attribute',\n",
       " 'variable',\n",
       " 'feature',\n",
       " 'consider',\n",
       " 'individual',\n",
       " 'tree',\n",
       " 'treei',\n",
       " 'different.2',\n",
       " 'immune',\n",
       " 'curse',\n",
       " 'dimensionality-',\n",
       " 'tree',\n",
       " 'consider',\n",
       " 'feature',\n",
       " 'featurespace',\n",
       " 'reduced.3',\n",
       " 'parallelization',\n",
       " 'tree',\n",
       " 'create',\n",
       " 'independently',\n",
       " 'different',\n",
       " 'datum',\n",
       " 'attribute',\n",
       " 'mean',\n",
       " 'thatwe',\n",
       " 'use',\n",
       " 'cpu',\n",
       " 'build',\n",
       " 'random',\n",
       " 'forests.4',\n",
       " 'train',\n",
       " 'test',\n",
       " 'split-',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'segregate',\n",
       " 'datum',\n",
       " 'train',\n",
       " 'test',\n",
       " 'willalway',\n",
       " '30',\n",
       " 'datum',\n",
       " 'decision',\n",
       " 'tree.5',\n",
       " 'stability-',\n",
       " 'stability',\n",
       " 'arise',\n",
       " 'result',\n",
       " 'base',\n",
       " 'majority',\n",
       " 'voting/',\n",
       " 'averaging',\n",
       " 'difference',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'random',\n",
       " 'forestrandom',\n",
       " 'forest',\n",
       " 'collection',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'lot',\n",
       " 'difference',\n",
       " 'behavior',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'random',\n",
       " 'forest1',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'normally',\n",
       " 'suffer',\n",
       " 'fromthe',\n",
       " 'problem',\n",
       " 'overfitte',\n",
       " '’',\n",
       " 'allowedto',\n",
       " 'grow',\n",
       " 'control.1',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'create',\n",
       " 'fromsubset',\n",
       " 'datum',\n",
       " 'final',\n",
       " 'output',\n",
       " 'isbase',\n",
       " 'average',\n",
       " 'majority',\n",
       " 'rankingand',\n",
       " 'problem',\n",
       " 'overfitte',\n",
       " 'istaken',\n",
       " 'care',\n",
       " 'of.2',\n",
       " 'single',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'fast',\n",
       " 'incomputation.2',\n",
       " 'comparatively',\n",
       " 'slower.3',\n",
       " 'data',\n",
       " 'set',\n",
       " 'feature',\n",
       " 'istaken',\n",
       " 'input',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'willformulate',\n",
       " 'set',\n",
       " 'rule',\n",
       " 'doprediction.3',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'randomly',\n",
       " 'selectsobservation',\n",
       " 'build',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'andthe',\n",
       " 'average',\n",
       " 'result',\n",
       " 'doesn’tuse',\n",
       " 'set',\n",
       " 'formula',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'successful',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'tree',\n",
       " 'diverse',\n",
       " 'andacceptable',\n",
       " 'important',\n",
       " 'hyperparametershyperparameters',\n",
       " 'use',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'enhance',\n",
       " 'performance',\n",
       " 'predictive',\n",
       " 'power',\n",
       " 'ofmodel',\n",
       " 'model',\n",
       " 'fast',\n",
       " 'follow',\n",
       " 'hyperparameter',\n",
       " 'increase',\n",
       " 'predictive',\n",
       " 'power:1',\n",
       " 'n_estimator',\n",
       " '–',\n",
       " 'number',\n",
       " 'tree',\n",
       " 'algorithm',\n",
       " 'build',\n",
       " 'average',\n",
       " 'predictions.2',\n",
       " 'max_features',\n",
       " '–',\n",
       " 'maximum',\n",
       " 'number',\n",
       " 'feature',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'consider',\n",
       " 'split',\n",
       " 'node.3',\n",
       " 'mini_sample_leaf',\n",
       " '–',\n",
       " 'determine',\n",
       " 'minimum',\n",
       " 'number',\n",
       " 'leave',\n",
       " 'require',\n",
       " 'split',\n",
       " 'internal',\n",
       " 'node',\n",
       " 'follow',\n",
       " 'hyperparameter',\n",
       " 'increase',\n",
       " 'speed:1',\n",
       " 'n_jobs',\n",
       " '–',\n",
       " 'tell',\n",
       " 'engine',\n",
       " 'processor',\n",
       " 'allow',\n",
       " 'use',\n",
       " 'value',\n",
       " '1',\n",
       " 'use',\n",
       " 'oneprocessor',\n",
       " 'value',\n",
       " '-1',\n",
       " 'limit.2',\n",
       " 'random_state',\n",
       " '–',\n",
       " 'control',\n",
       " 'randomness',\n",
       " 'sample',\n",
       " 'model',\n",
       " 'produce',\n",
       " 'result',\n",
       " 'itha',\n",
       " 'definite',\n",
       " 'value',\n",
       " 'random',\n",
       " 'state',\n",
       " 'hyperparameter',\n",
       " 'sametraine',\n",
       " 'datum',\n",
       " '3',\n",
       " 'oob_score',\n",
       " '–',\n",
       " 'oob',\n",
       " 'mean',\n",
       " 'bag',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'cross',\n",
       " 'validation',\n",
       " 'method',\n",
       " 'thirdof',\n",
       " 'sample',\n",
       " 'use',\n",
       " 'train',\n",
       " 'datum',\n",
       " 'instead',\n",
       " 'use',\n",
       " 'evaluate',\n",
       " 'performance',\n",
       " 'sample',\n",
       " 'arecalle',\n",
       " 'bag',\n",
       " 'sample',\n",
       " 'code',\n",
       " 'python',\n",
       " '–',\n",
       " 'random',\n",
       " 'forestnow',\n",
       " 'let',\n",
       " 'understand',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'help',\n",
       " 'code.1',\n",
       " 'let',\n",
       " 'import',\n",
       " 'library',\n",
       " 'import',\n",
       " 'require',\n",
       " 'library',\n",
       " 'import',\n",
       " 'panda',\n",
       " 'pd',\n",
       " 'numpy',\n",
       " 'np',\n",
       " 'import',\n",
       " 'matplotlib.pyplot',\n",
       " 'plt',\n",
       " 'seaborna',\n",
       " 'sns',\n",
       " 'matplotlib',\n",
       " 'inline2',\n",
       " 'import',\n",
       " 'dataset',\n",
       " 'read',\n",
       " 'csv',\n",
       " 'file',\n",
       " 'df',\n",
       " 'object',\n",
       " 'df',\n",
       " \"pd.read_csv('heart_v2.csv\",\n",
       " 'df.head()3',\n",
       " 'feature',\n",
       " 'variable',\n",
       " 'x',\n",
       " 'target',\n",
       " 'variable',\n",
       " 'y.',\n",
       " 'feature',\n",
       " 'variable',\n",
       " 'x',\n",
       " 'x',\n",
       " \"df.drop('heart\",\n",
       " \"disease',axis=1\",\n",
       " 'response',\n",
       " 'variable',\n",
       " 'y',\n",
       " 'y',\n",
       " \"df['heart\",\n",
       " \"disease']4\",\n",
       " 'train',\n",
       " 'test',\n",
       " 'split',\n",
       " 'perform',\n",
       " 'lets',\n",
       " 'split',\n",
       " 'datum',\n",
       " 'train',\n",
       " 'test',\n",
       " 'sklearn.model_selection',\n",
       " 'import',\n",
       " 'train_test_split',\n",
       " 'split',\n",
       " 'datum',\n",
       " 'train',\n",
       " 'test',\n",
       " 'x_train',\n",
       " 'x_t',\n",
       " 'y_train',\n",
       " 'y_t',\n",
       " 'train_test_split(x',\n",
       " 'y',\n",
       " 'train_size=0.7',\n",
       " 'random_state=42',\n",
       " 'x_train.shape',\n",
       " 'x_test.shape3',\n",
       " 'let',\n",
       " 'import',\n",
       " 'randomforestclassifier',\n",
       " 'fit',\n",
       " 'datum',\n",
       " 'sklearn.ensemble',\n",
       " 'import',\n",
       " 'randomforestclassifierclassifier_rf',\n",
       " 'randomforestclassifier(random_state=42',\n",
       " 'n_jobs=-1',\n",
       " 'max_depth=5',\n",
       " 'n_estimators=100,oob_score',\n",
       " 'true)%%time',\n",
       " 'classifier_rf.fit(x_train',\n",
       " 'y_train',\n",
       " 'check',\n",
       " 'oob',\n",
       " 'score',\n",
       " 'classifier_rf.oob_score_4',\n",
       " 'let',\n",
       " 'hyperparameter',\n",
       " 'tune',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'use',\n",
       " 'gridsearchcv',\n",
       " 'fit',\n",
       " 'data.rf',\n",
       " 'randomforestclassifier(random_state=42',\n",
       " 'n_jobs=-1)params',\n",
       " 'max_depth',\n",
       " '2,3,5,10,20',\n",
       " 'min_samples_leaf',\n",
       " '5,10,20,50,100,200',\n",
       " \"n_estimators':[10,25,30,50,100,200\",\n",
       " 'sklearn.model_selection',\n",
       " 'import',\n",
       " 'gridsearchcv',\n",
       " 'instantiate',\n",
       " 'grid',\n",
       " 'search',\n",
       " 'model',\n",
       " 'grid_search',\n",
       " 'gridsearchcv(estimator',\n",
       " 'rf',\n",
       " 'param_grid',\n",
       " 'param',\n",
       " 'cv',\n",
       " '4,n_jobs=-1',\n",
       " 'verbose=1',\n",
       " 'scoring=\"accuracy\")%%time',\n",
       " 'grid_search.fit(x_train',\n",
       " 'y_train)grid_search.best_score',\n",
       " 'rf_b',\n",
       " 'grid_search.best_estimator',\n",
       " 'rf_bestfrom',\n",
       " 'hyperparameter',\n",
       " 'tuning',\n",
       " 'fetch',\n",
       " 'good',\n",
       " 'estimator',\n",
       " 'good',\n",
       " 'set',\n",
       " 'parametersidentified',\n",
       " 'max_depth=5',\n",
       " 'min_samples_leaf=10,n_estimators=105',\n",
       " 'let',\n",
       " 'visualizefrom',\n",
       " 'sklearn.tree',\n",
       " 'import',\n",
       " 'plot_tree',\n",
       " 'plt.figure(figsize=(80,40',\n",
       " 'plot_tree(rf_best.estimators_[5],feature_name',\n",
       " 'x.columns',\n",
       " \"class_names=['disease\",\n",
       " 'disease\"],filled',\n",
       " 'true',\n",
       " 'sklearn.tree',\n",
       " 'import',\n",
       " 'plot_tree',\n",
       " 'plt.figure(figsize=(80,40',\n",
       " 'plot_tree(rf_best.estimators_[7],feature_name',\n",
       " 'x.columns',\n",
       " \"class_names=['disease\",\n",
       " 'disease\"],filled',\n",
       " 'true',\n",
       " 'tree',\n",
       " 'create',\n",
       " 'estimators_[5',\n",
       " 'estimators_[7',\n",
       " 'different',\n",
       " 'tree',\n",
       " 'isindependent',\n",
       " 'other.6',\n",
       " 'let',\n",
       " 'sort',\n",
       " 'datum',\n",
       " 'help',\n",
       " 'feature',\n",
       " 'importancerf_best.feature_importance',\n",
       " 'imp_df',\n",
       " 'pd',\n",
       " 'dataframe',\n",
       " 'varname',\n",
       " 'x_train.columns',\n",
       " 'imp',\n",
       " 'rf_best.feature_importance',\n",
       " 'imp_df.sort_values(by=\"imp',\n",
       " 'ascend',\n",
       " 'false',\n",
       " 'use',\n",
       " 'casesthis',\n",
       " 'algorithm',\n",
       " 'widely',\n",
       " 'use',\n",
       " 'e',\n",
       " 'commerce',\n",
       " 'banking',\n",
       " 'medicine',\n",
       " 'stock',\n",
       " 'market',\n",
       " 'etc',\n",
       " 'example',\n",
       " 'banking',\n",
       " 'industry',\n",
       " 'use',\n",
       " 'find',\n",
       " 'customer',\n",
       " 'default',\n",
       " 'loan',\n",
       " 'advantage',\n",
       " 'disadvantages',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'algorithmadvantages',\n",
       " '1',\n",
       " 'use',\n",
       " 'classification',\n",
       " 'regression',\n",
       " 'problems.2',\n",
       " 'solve',\n",
       " 'problem',\n",
       " 'overfitting',\n",
       " 'output',\n",
       " 'base',\n",
       " 'majority',\n",
       " 'voting',\n",
       " 'averaging.3',\n",
       " 'perform',\n",
       " 'datum',\n",
       " 'contain',\n",
       " 'null',\n",
       " 'miss',\n",
       " 'values.4',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'create',\n",
       " 'independent',\n",
       " 'property',\n",
       " 'parallelization.5',\n",
       " 'highly',\n",
       " 'stable',\n",
       " 'average',\n",
       " 'answer',\n",
       " 'large',\n",
       " 'number',\n",
       " 'tree',\n",
       " 'taken.6',\n",
       " 'maintain',\n",
       " 'diversity',\n",
       " 'attribute',\n",
       " 'consider',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'itis',\n",
       " 'true',\n",
       " 'cases.7',\n",
       " 'immune',\n",
       " 'curse',\n",
       " 'dimensionality',\n",
       " 'tree',\n",
       " 'consider',\n",
       " 'attribute',\n",
       " 'featurespace',\n",
       " 'reduced.8',\n",
       " 'segregate',\n",
       " 'datum',\n",
       " 'train',\n",
       " 'test',\n",
       " '30',\n",
       " 'datum',\n",
       " 'notseen',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'bootstrap',\n",
       " 'disadvantages1',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'highly',\n",
       " 'complex',\n",
       " 'compare',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'decision',\n",
       " 'byfollowe',\n",
       " 'path',\n",
       " 'tree.2',\n",
       " 'training',\n",
       " 'time',\n",
       " 'compare',\n",
       " 'model',\n",
       " 'complexity',\n",
       " 'aprediction',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'generate',\n",
       " 'output',\n",
       " 'input',\n",
       " 'datum',\n",
       " 'summarynow',\n",
       " 'conclude',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'good',\n",
       " 'technique',\n",
       " 'high',\n",
       " 'performance',\n",
       " 'iswidely',\n",
       " 'use',\n",
       " 'industry',\n",
       " 'efficiency',\n",
       " 'handle',\n",
       " 'binary',\n",
       " 'continuous',\n",
       " 'categorical',\n",
       " 'datum',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'great',\n",
       " 'choice',\n",
       " 'want',\n",
       " 'build',\n",
       " 'model',\n",
       " 'fast',\n",
       " 'efficiently',\n",
       " 'bestthing',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'handle',\n",
       " 'missing',\n",
       " 'value',\n",
       " 'overall',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'fast',\n",
       " 'simple',\n",
       " 'flexible',\n",
       " 'robust',\n",
       " 'model',\n",
       " 'limitation',\n",
       " 'visit',\n",
       " 'follow',\n",
       " 'link',\n",
       " 'understanding',\n",
       " 'reading!!!i',\n",
       " 'hope',\n",
       " 'enjoy',\n",
       " 'read',\n",
       " 'article',\n",
       " 'increase',\n",
       " 'knowledge',\n",
       " 'random',\n",
       " 'forest',\n",
       " 'mention',\n",
       " 'want',\n",
       " 'share',\n",
       " 'thought',\n",
       " 'feel',\n",
       " 'free',\n",
       " 'comment',\n",
       " 'thecomment',\n",
       " 'section',\n",
       " 'authorsruthi',\n",
       " 'e',\n",
       " 'ri’m',\n",
       " 'data',\n",
       " 'science',\n",
       " 'enthusiast',\n",
       " 'interest',\n",
       " 'datum',\n",
       " 'analysis',\n",
       " 'visualization',\n",
       " 'currently',\n",
       " 'pursue',\n",
       " 'datascience',\n",
       " 'course',\n",
       " 'iiit',\n",
       " 'bangalore',\n",
       " 'come',\n",
       " 'civil',\n",
       " 'engineering',\n",
       " 'background',\n",
       " '4',\n",
       " 'year',\n",
       " 'experiencein',\n",
       " 'construction',\n",
       " 'industry',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = ' '.join(df['processed_text']).split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13ebaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understand random forestthis article publish data science blogathonintroductionrandom forest supervised machine learning algorithm use widely classification andregression problem build decision tree different sample majority vote forclassification average case regression important feature random forest algorithm handle datum setcontaine continuous variable case regression categorical variable case ofclassification perform result classification problem real life analogylet dive real life analogy understand concept far student x want choose acourse 10 2 confused choice course base skill set decidesto consult people like cousin teacher parent degree student work people asksthem varied question like choose job opportunity course course fee etc finally consult people course decide course suggest mostof people work random forest algorithmbefore understand working random forest look ensemble technique ensemble simply mean combine multiple model collection model use makeprediction individual model ensemble use type methods:1 bagging – create different training subset sample training datum replacement finaloutput base majority voting example random forest advancedalgorithmclassificationmachine learningprojectpythonregressionstructure datasupervised 2 boost – combine weak learner strong learner create sequential model thefinal model high accuracy example ada boost xg boostas mention early random forest work bagging principle let dive understandbagging detail baggingbagging know bootstrap aggregation ensemble technique use random forest baggingchoose random sample datum set model generate sample bootstrapsamples provide original data replacement know row sampling step rowsample replacement bootstrap model train independently generatesresult final output base majority voting combine result model stepwhich involve combine result generate output base majority voting knownas aggregation let look example break help follow figure bootstrapsample actual datum bootstrap sample 01 bootstrap sample 02 bootstrap sample 03)with replacement mean high possibility sample contain unique datum model model 01 model 02 model 03 obtain bootstrap sample trainedindependently model generate result happy emoji majority whencompare sad emoji base majority vote final output obtain happy emoji step involve random forest algorithm step 1 random forest n number random record datum set k number ofrecord step 2 individual decision tree construct sample step 3 decision tree generate output step 4 final output consider base majority voting averaging classification regressionrespectively example consider fruit basket datum figure n number samplesare fruit basket individual decision tree construct sample eachdecision tree generate output figure final output consider base onmajority voting figure majority decision tree output applewhen compare banana final output apple important features random forest1 diversity- attribute variable feature consider individual tree treei different.2 immune curse dimensionality- tree consider feature featurespace reduced.3 parallelization tree create independently different datum attribute mean thatwe use cpu build random forests.4 train test split- random forest segregate datum train test willalway 30 datum decision tree.5 stability- stability arise result base majority voting/ averaging difference decision tree random forestrandom forest collection decision tree lot difference behavior decision tree random forest1 decision tree normally suffer fromthe problem overfitte ’ allowedto grow control.1 random forest create fromsubset datum final output isbase average majority rankingand problem overfitte istaken care of.2 single decision tree fast incomputation.2 comparatively slower.3 data set feature istaken input decision tree willformulate set rule doprediction.3 random forest randomly selectsobservation build decision tree andthe average result doesn’tuse set formula random forest successful decision tree tree diverse andacceptable important hyperparametershyperparameters use random forest enhance performance predictive power ofmodel model fast follow hyperparameter increase predictive power:1 n_estimator – number tree algorithm build average predictions.2 max_features – maximum number feature random forest consider split node.3 mini_sample_leaf – determine minimum number leave require split internal node follow hyperparameter increase speed:1 n_jobs – tell engine processor allow use value 1 use oneprocessor value -1 limit.2 random_state – control randomness sample model produce result itha definite value random state hyperparameter sametraine datum 3 oob_score – oob mean bag random forest cross validation method thirdof sample use train datum instead use evaluate performance sample arecalle bag sample code python – random forestnow let understand random forest help code.1 let import library import require library import panda pd numpy np import matplotlib.pyplot plt seaborna sns matplotlib inline2 import dataset read csv file df object df pd.read_csv('heart_v2.csv df.head()3 feature variable x target variable y. feature variable x x df.drop('heart disease',axis=1 response variable y y df['heart disease']4 train test split perform lets split datum train test sklearn.model_selection import train_test_split split datum train test x_train x_t y_train y_t train_test_split(x y train_size=0.7 random_state=42 x_train.shape x_test.shape3 let import randomforestclassifier fit datum sklearn.ensemble import randomforestclassifierclassifier_rf randomforestclassifier(random_state=42 n_jobs=-1 max_depth=5 n_estimators=100,oob_score true)%%time classifier_rf.fit(x_train y_train check oob score classifier_rf.oob_score_4 let hyperparameter tune random forest use gridsearchcv fit data.rf randomforestclassifier(random_state=42 n_jobs=-1)params max_depth 2,3,5,10,20 min_samples_leaf 5,10,20,50,100,200 n_estimators':[10,25,30,50,100,200 sklearn.model_selection import gridsearchcv instantiate grid search model grid_search gridsearchcv(estimator rf param_grid param cv 4,n_jobs=-1 verbose=1 scoring=\"accuracy\")%%time grid_search.fit(x_train y_train)grid_search.best_score rf_b grid_search.best_estimator rf_bestfrom hyperparameter tuning fetch good estimator good set parametersidentified max_depth=5 min_samples_leaf=10,n_estimators=105 let visualizefrom sklearn.tree import plot_tree plt.figure(figsize=(80,40 plot_tree(rf_best.estimators_[5],feature_name x.columns class_names=['disease disease\"],filled true sklearn.tree import plot_tree plt.figure(figsize=(80,40 plot_tree(rf_best.estimators_[7],feature_name x.columns class_names=['disease disease\"],filled true tree create estimators_[5 estimators_[7 different tree isindependent other.6 let sort datum help feature importancerf_best.feature_importance imp_df pd dataframe varname x_train.columns imp rf_best.feature_importance imp_df.sort_values(by=\"imp ascend false use casesthis algorithm widely use e commerce banking medicine stock market etc example banking industry use find customer default loan advantage disadvantages random forest algorithmadvantages 1 use classification regression problems.2 solve problem overfitting output base majority voting averaging.3 perform datum contain null miss values.4 decision tree create independent property parallelization.5 highly stable average answer large number tree taken.6 maintain diversity attribute consider decision tree itis true cases.7 immune curse dimensionality tree consider attribute featurespace reduced.8 segregate datum train test 30 datum notseen decision tree bootstrap disadvantages1 random forest highly complex compare decision tree decision byfollowe path tree.2 training time compare model complexity aprediction decision tree generate output input datum summarynow conclude random forest good technique high performance iswidely use industry efficiency handle binary continuous categorical datum random forest great choice want build model fast efficiently bestthing random forest handle missing value overall random forest fast simple flexible robust model limitation visit follow link understanding reading!!!i hope enjoy read article increase knowledge random forest mention want share thought feel free comment thecomment section authorsruthi e ri’m data science enthusiast interest datum analysis visualization currently pursue datascience course iiit bangalore come civil engineering background 4 year experiencein construction industry feel free contact linkedin medium article analytics vidhya use author’sdiscretion article url "
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(token, end =\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef882ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tree</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forest</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datum</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>use</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>output</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>majority</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "0    random     33\n",
       "1      tree     28\n",
       "2    forest     26\n",
       "3     datum     23\n",
       "4  decision     20\n",
       "5     model     19\n",
       "6       use     17\n",
       "7    sample     15\n",
       "8    output     12\n",
       "9  majority     11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(tokens, columns=['word']).value_counts().reset_index()\n",
    "word_counts.columns = ['word', 'count']\n",
    "\n",
    "word_counts = word_counts.sort_values(by='count', ascending=False)\n",
    "word_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc66e31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most repeated word in that pdf is: random\n"
     ]
    }
   ],
   "source": [
    "print(f\"The most repeated word in that pdf is: {word_counts['word'][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
